{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# einops: phi & qwen\n",
    "# sentencepiece: llama\n",
    "# tiktoken & transformers_stream_generator: qwen\n",
    "!pip install transformers trl wandb einops sentencepiece tiktoken transformers_stream_generator==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# when using quantized models\n",
    "\n",
    "!pip install auto-gptq optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only on first run.\n",
    "\n",
    "import os\n",
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()  # Write a config file\n",
    "os._exit(00)  # Restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "\n",
    "torch.distributed.init_process_group(backend='nccl', world_size=1, rank=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from trl import PPOConfig\n",
    "\n",
    "config = PPOConfig(\n",
    "            model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "            reward_model=\"text-classification:Hello-SimpleAI/chatgpt-detector-roberta\",\n",
    "            learning_rate=1.41e-5,\n",
    "            log_with=\"wandb\", \n",
    "            mini_batch_size=8, # really important for memory\n",
    "            batch_size=128, \n",
    "            gradient_accumulation_steps=1,\n",
    "            early_stopping=False,\n",
    "            target_kl=6.0,\n",
    "            kl_penalty=\"kl\",\n",
    "            seed=0,\n",
    "            use_score_scaling=False,\n",
    "            use_score_norm=False,\n",
    "            score_clip=None,\n",
    "        )\n",
    "\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16, \"max_length\": 512, \"truncation\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "LlamaTokenizerFast is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:286\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/LlamaTokenizerFast/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1368\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:409\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 409\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:323\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    315\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-65da1a48-317336887b22e8fb43abdb3e;c1b18349-de00-4830-baef-dcba72875d15)\n\nRepository Not Found for url: https://huggingface.co/LlamaTokenizerFast/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLlamaTokenizerFast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:767\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    769\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:600\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    599\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 600\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: LlamaTokenizerFast is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LlamaTokenizerFast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, AutoTokenizer\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(config.model_name, trust_remote_code=True, padding_side='left')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name,\n",
    "                                          padding_side='left',\n",
    "                                          trust_remote_code=True) \n",
    "if getattr(tokenizer, \"pad_token\", None) is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 3857/3857 [00:02<00:00, 1587.90 examples/s]\n",
      "Filter: 100%|██████████████████████████████████████████████████████████████| 3857/3857 [00:00<00:00, 6033.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset import build_dataset\n",
    "# from dataset import build_dataset_for_gemma\n",
    "\n",
    "dataset = build_dataset(tokenizer)\n",
    "# dataset = build_dataset_for_gemma(tokenizer)\n",
    "    \n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = dataset[0]['input_ids'].to('cuda')\n",
    "test1 = model.generate(inputs, **generation_kwargs)  \n",
    "test2 = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[INST] <<SYS>>\\nYou are an assistant who gives detailed and long answers\\n<</SYS>>\\n\\nexplain Tuckman's stages of group development [/INST]  Ah, an excellent topic! Tuckman's stages of group development is a theory that explains the different stages a group goes through as they form and mature. The theory was first proposed by Bruce Tuckman in 1965 and has since been widely accepted and used in various fields. Here are the five stages of group development, along with some key characteristics of each stage:\\n\\n1. **Forming**: This is the initial stage of group development, where members come together to form a new group. During this stage, the group is characterized by a high level of dependency on the leader, as members rely on the leader to provide direction and guidance. The group may also experience a sense of uncertainty and insecurity, as they try to figure out their roles and responsibilities within the group.\\n\\nKey characteristics:\\n\\n* High dependency on the leader\\n* Uncertainty and insecurity among members\\n* Focus on understanding roles and responsibilities\\n2. **Storming**: As the group becomes more comfortable with one another, they begin to explore their differences and conflicts. This stage is characterized by a high level of conflict and negotiation among members, as they try to establish their roles and boundaries. The group may also experience a sense of frustration and anger, as they struggle to find a common ground.\\n\\nKey characteristics:\\n\\n* High level of conflict and negotiation\\n* Establishment of roles and boundaries\\n* Sense of frustration and anger\\n3. **Norming**: Once the group has established their roles and boundaries, they begin to work together more effectively. This stage is characterized by a sense of stability and cohesion, as members begin to understand and respect one another's perspectives. The group may also experience a sense of relief and satisfaction, as they start to see the benefits of working together.\\n\\nKey characteristics:\\n\\n* Stability and cohesion\\n* Understanding and respect for one another's perspectives\\n* Sense of relief and satisfaction\\n4. **Performing**: In this final stage, the group is able to function at its highest level. Members are able to work together effectively, sharing knowledge and skills, and achieving their goals. The group is characterized by a high level of cohesion and communication, as members feel comfortable and confident in their roles.\\n\\nKey characteristics:\\n\\n* Effect\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(test1, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|█████████████████████████████████████████████████████████████████████| 614/614 [00:00<00:00, 4.45MB/s]\n",
      "model.safetensors.index.json: 100%|█████████████████████████████████████████████████| 26.8k/26.8k [00:00<00:00, 161MB/s]\n",
      "Downloading shards:   0%|                                                                         | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|                                                     | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|                                             | 21.0M/9.98G [00:00<01:05, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|▏                                            | 41.9M/9.98G [00:00<01:01, 162MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▎                                            | 62.9M/9.98G [00:00<01:00, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▍                                            | 83.9M/9.98G [00:00<00:59, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▍                                             | 105M/9.98G [00:00<00:59, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▌                                             | 126M/9.98G [00:00<00:58, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▋                                             | 147M/9.98G [00:00<00:58, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|▊                                             | 168M/9.98G [00:00<00:56, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|▊                                             | 189M/9.98G [00:01<00:55, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|▉                                             | 210M/9.98G [00:01<00:55, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|█                                             | 231M/9.98G [00:01<00:56, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|█▏                                            | 252M/9.98G [00:01<00:55, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|█▎                                            | 273M/9.98G [00:01<00:55, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|█▎                                            | 294M/9.98G [00:01<00:56, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|█▍                                            | 315M/9.98G [00:01<00:56, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|█▌                                            | 336M/9.98G [00:01<00:55, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|█▋                                            | 357M/9.98G [00:02<00:56, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|█▋                                            | 377M/9.98G [00:02<00:55, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|█▊                                            | 398M/9.98G [00:02<00:55, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|█▉                                            | 419M/9.98G [00:02<00:55, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|██                                            | 440M/9.98G [00:02<00:55, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|██▏                                           | 461M/9.98G [00:02<00:55, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|██▏                                           | 482M/9.98G [00:02<00:54, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|██▎                                           | 503M/9.98G [00:02<00:56, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|██▍                                           | 524M/9.98G [00:03<00:56, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|██▌                                           | 545M/9.98G [00:03<00:54, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|██▌                                           | 566M/9.98G [00:03<00:54, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|██▋                                           | 587M/9.98G [00:03<00:54, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|██▊                                           | 608M/9.98G [00:03<00:54, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|██▉                                           | 629M/9.98G [00:03<00:54, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|██▉                                           | 650M/9.98G [00:03<00:53, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|███                                           | 671M/9.98G [00:03<00:53, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|███▏                                          | 692M/9.98G [00:04<00:53, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|███▎                                          | 713M/9.98G [00:04<00:53, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|███▍                                          | 734M/9.98G [00:04<00:52, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|███▍                                          | 755M/9.98G [00:04<00:53, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|███▌                                          | 776M/9.98G [00:04<00:54, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|███▋                                          | 797M/9.98G [00:04<00:54, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|███▊                                          | 818M/9.98G [00:04<01:10, 131MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|███▊                                          | 839M/9.98G [00:05<01:05, 141MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|███▉                                          | 860M/9.98G [00:05<01:00, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|████                                          | 881M/9.98G [00:05<00:57, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|████▏                                         | 902M/9.98G [00:05<00:56, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|████▎                                         | 923M/9.98G [00:05<00:54, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|████▎                                         | 944M/9.98G [00:05<00:53, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|████▍                                         | 965M/9.98G [00:05<00:52, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|████▌                                         | 986M/9.98G [00:05<00:52, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|████▌                                        | 1.01G/9.98G [00:05<00:52, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|████▋                                        | 1.03G/9.98G [00:06<00:51, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|████▋                                        | 1.05G/9.98G [00:06<00:52, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|████▊                                        | 1.07G/9.98G [00:06<00:51, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|████▉                                        | 1.09G/9.98G [00:06<00:50, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|█████                                        | 1.11G/9.98G [00:06<00:50, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|█████                                        | 1.13G/9.98G [00:06<00:50, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█████▏                                       | 1.15G/9.98G [00:06<00:50, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█████▎                                       | 1.17G/9.98G [00:06<00:50, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█████▍                                       | 1.20G/9.98G [00:07<00:50, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█████▍                                       | 1.22G/9.98G [00:07<00:50, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█████▌                                       | 1.24G/9.98G [00:07<00:50, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█████▋                                       | 1.26G/9.98G [00:07<00:50, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█████▊                                       | 1.28G/9.98G [00:07<00:51, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█████▊                                       | 1.30G/9.98G [00:07<01:11, 122MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█████▉                                       | 1.32G/9.98G [00:07<01:05, 132MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|██████                                       | 1.34G/9.98G [00:08<01:00, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|██████▏                                      | 1.36G/9.98G [00:08<00:58, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|██████▏                                      | 1.38G/9.98G [00:08<00:57, 151MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|██████▎                                      | 1.41G/9.98G [00:08<00:54, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|██████▍                                      | 1.43G/9.98G [00:08<00:53, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|██████▌                                      | 1.45G/9.98G [00:08<00:51, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|██████▌                                      | 1.47G/9.98G [00:08<00:50, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|██████▋                                      | 1.49G/9.98G [00:08<00:50, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|██████▊                                      | 1.51G/9.98G [00:09<00:49, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|██████▉                                      | 1.53G/9.98G [00:09<00:59, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|██████▉                                      | 1.55G/9.98G [00:09<00:56, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|███████                                      | 1.57G/9.98G [00:09<00:53, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|███████▏                                     | 1.59G/9.98G [00:09<00:52, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|███████▎                                     | 1.61G/9.98G [00:09<00:50, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|███████▍                                     | 1.64G/9.98G [00:09<00:50, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|███████▍                                     | 1.66G/9.98G [00:10<00:50, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|███████▌                                     | 1.68G/9.98G [00:10<00:50, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|███████▋                                     | 1.70G/9.98G [00:10<00:49, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|███████▊                                     | 1.72G/9.98G [00:10<00:49, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|███████▊                                     | 1.74G/9.98G [00:10<00:49, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|███████▉                                     | 1.76G/9.98G [00:10<00:49, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|████████                                     | 1.78G/9.98G [00:10<00:48, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|████████▏                                    | 1.80G/9.98G [00:10<00:48, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|████████▏                                    | 1.82G/9.98G [00:11<00:48, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|████████▎                                    | 1.85G/9.98G [00:11<00:47, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|████████▍                                    | 1.87G/9.98G [00:11<00:47, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|████████▌                                    | 1.89G/9.98G [00:11<00:46, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|████████▌                                    | 1.91G/9.98G [00:11<00:46, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|████████▋                                    | 1.93G/9.98G [00:11<00:46, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|████████▊                                    | 1.95G/9.98G [00:11<00:46, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|████████▉                                    | 1.97G/9.98G [00:11<00:47, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|████████▉                                    | 1.99G/9.98G [00:12<00:47, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|█████████                                    | 2.01G/9.98G [00:12<00:46, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|█████████▏                                   | 2.03G/9.98G [00:12<00:45, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|█████████▎                                   | 2.06G/9.98G [00:12<00:45, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|█████████▎                                   | 2.08G/9.98G [00:12<00:46, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|█████████▍                                   | 2.10G/9.98G [00:12<00:45, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|█████████▌                                   | 2.12G/9.98G [00:12<00:45, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|█████████▋                                   | 2.14G/9.98G [00:12<00:44, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|█████████▋                                   | 2.16G/9.98G [00:12<00:45, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|█████████▊                                   | 2.18G/9.98G [00:13<00:45, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|█████████▉                                   | 2.20G/9.98G [00:13<00:44, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|██████████                                   | 2.22G/9.98G [00:13<00:45, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|██████████                                   | 2.24G/9.98G [00:13<00:44, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|██████████▏                                  | 2.26G/9.98G [00:13<00:44, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|██████████▎                                  | 2.29G/9.98G [00:13<00:44, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|██████████▍                                  | 2.31G/9.98G [00:13<00:44, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|██████████▍                                  | 2.33G/9.98G [00:13<00:43, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██████████▌                                  | 2.35G/9.98G [00:14<00:43, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██████████▋                                  | 2.37G/9.98G [00:14<00:44, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██████████▊                                  | 2.39G/9.98G [00:14<00:43, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██████████▉                                  | 2.41G/9.98G [00:14<00:43, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██████████▉                                  | 2.43G/9.98G [00:14<00:43, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|███████████                                  | 2.45G/9.98G [00:14<00:43, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|███████████▏                                 | 2.47G/9.98G [00:14<00:43, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|███████████▎                                 | 2.50G/9.98G [00:15<01:06, 113MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|███████████▎                                 | 2.52G/9.98G [00:15<00:59, 125MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|███████████▍                                 | 2.54G/9.98G [00:15<00:54, 138MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|███████████▌                                 | 2.56G/9.98G [00:15<00:51, 145MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|███████████▋                                 | 2.58G/9.98G [00:15<00:48, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|███████████▋                                 | 2.60G/9.98G [00:15<00:46, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|███████████▊                                 | 2.62G/9.98G [00:15<00:44, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|███████████▉                                 | 2.64G/9.98G [00:15<00:44, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|████████████                                 | 2.66G/9.98G [00:16<00:42, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|████████████                                 | 2.68G/9.98G [00:16<00:41, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|████████████▏                                | 2.71G/9.98G [00:16<00:42, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|████████████▎                                | 2.73G/9.98G [00:16<00:42, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|████████████▍                                | 2.75G/9.98G [00:16<00:42, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|████████████▍                                | 2.77G/9.98G [00:16<00:41, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|████████████▌                                | 2.79G/9.98G [00:16<00:41, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|████████████▋                                | 2.81G/9.98G [00:16<00:41, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|████████████▊                                | 2.83G/9.98G [00:17<00:41, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|████████████▊                                | 2.85G/9.98G [00:17<00:40, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|████████████▉                                | 2.87G/9.98G [00:17<00:41, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█████████████                                | 2.89G/9.98G [00:17<00:41, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█████████████▏                               | 2.92G/9.98G [00:17<00:42, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█████████████▏                               | 2.94G/9.98G [00:17<00:42, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█████████████▎                               | 2.96G/9.98G [00:17<00:42, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█████████████▍                               | 2.98G/9.98G [00:17<00:41, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█████████████▌                               | 3.00G/9.98G [00:18<00:40, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█████████████▌                               | 3.02G/9.98G [00:18<00:39, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█████████████▋                               | 3.04G/9.98G [00:18<00:39, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█████████████▊                               | 3.06G/9.98G [00:18<00:39, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█████████████▉                               | 3.08G/9.98G [00:18<00:39, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█████████████▉                               | 3.10G/9.98G [00:18<00:39, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|██████████████                               | 3.12G/9.98G [00:18<00:39, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|██████████████▏                              | 3.15G/9.98G [00:18<00:39, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|██████████████▎                              | 3.17G/9.98G [00:19<00:40, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|██████████████▍                              | 3.19G/9.98G [00:19<00:40, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|██████████████▍                              | 3.21G/9.98G [00:19<00:40, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|██████████████▌                              | 3.23G/9.98G [00:19<00:39, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|██████████████▋                              | 3.25G/9.98G [00:19<00:39, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|██████████████▊                              | 3.27G/9.98G [00:19<00:39, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|██████████████▊                              | 3.29G/9.98G [00:19<00:38, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|██████████████▉                              | 3.31G/9.98G [00:19<00:38, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|███████████████                              | 3.33G/9.98G [00:20<00:38, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███████████████▏                             | 3.36G/9.98G [00:20<00:38, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███████████████▏                             | 3.38G/9.98G [00:20<00:37, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███████████████▎                             | 3.40G/9.98G [00:20<00:36, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███████████████▍                             | 3.42G/9.98G [00:20<00:37, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███████████████▌                             | 3.44G/9.98G [00:20<00:37, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|███████████████▌                             | 3.46G/9.98G [00:20<00:36, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|███████████████▋                             | 3.48G/9.98G [00:20<00:41, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|███████████████▊                             | 3.50G/9.98G [00:21<00:40, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|███████████████▉                             | 3.52G/9.98G [00:21<00:39, 163MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|███████████████▉                             | 3.54G/9.98G [00:21<00:38, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|████████████████                             | 3.57G/9.98G [00:21<00:37, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|████████████████▏                            | 3.59G/9.98G [00:21<00:36, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|████████████████▎                            | 3.61G/9.98G [00:21<00:37, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|████████████████▎                            | 3.63G/9.98G [00:21<00:37, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|████████████████▍                            | 3.65G/9.98G [00:21<00:38, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|████████████████▌                            | 3.67G/9.98G [00:21<00:37, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|████████████████▋                            | 3.69G/9.98G [00:22<00:36, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|████████████████▋                            | 3.71G/9.98G [00:22<00:36, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|████████████████▊                            | 3.73G/9.98G [00:22<00:36, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|████████████████▉                            | 3.75G/9.98G [00:22<00:36, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█████████████████                            | 3.77G/9.98G [00:22<00:35, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█████████████████                            | 3.80G/9.98G [00:22<00:35, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█████████████████▏                           | 3.82G/9.98G [00:22<00:35, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█████████████████▎                           | 3.84G/9.98G [00:22<00:35, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█████████████████▍                           | 3.86G/9.98G [00:23<00:35, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█████████████████▍                           | 3.88G/9.98G [00:23<00:35, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█████████████████▌                           | 3.90G/9.98G [00:23<00:34, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█████████████████▋                           | 3.92G/9.98G [00:23<00:34, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█████████████████▊                           | 3.94G/9.98G [00:23<00:33, 181MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█████████████████▉                           | 3.96G/9.98G [00:23<00:33, 179MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█████████████████▉                           | 3.98G/9.98G [00:23<00:33, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|██████████████████                           | 4.01G/9.98G [00:23<00:33, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|██████████████████▏                          | 4.03G/9.98G [00:24<00:33, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|██████████████████▎                          | 4.05G/9.98G [00:24<00:33, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|██████████████████▎                          | 4.07G/9.98G [00:24<00:33, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|██████████████████▍                          | 4.09G/9.98G [00:24<00:33, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|██████████████████▌                          | 4.11G/9.98G [00:24<00:33, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|██████████████████▋                          | 4.13G/9.98G [00:24<00:33, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|██████████████████▋                          | 4.15G/9.98G [00:24<00:33, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|██████████████████▊                          | 4.17G/9.98G [00:24<00:33, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|██████████████████▉                          | 4.19G/9.98G [00:24<00:33, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|███████████████████                          | 4.22G/9.98G [00:25<00:32, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|███████████████████                          | 4.24G/9.98G [00:25<00:32, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|███████████████████▏                         | 4.26G/9.98G [00:25<00:33, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|███████████████████▎                         | 4.28G/9.98G [00:25<00:33, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|███████████████████▍                         | 4.30G/9.98G [00:25<00:33, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|███████████████████▍                         | 4.32G/9.98G [00:25<00:32, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|███████████████████▌                         | 4.34G/9.98G [00:25<00:32, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|███████████████████▋                         | 4.36G/9.98G [00:25<00:32, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|███████████████████▊                         | 4.38G/9.98G [00:26<00:32, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|███████████████████▊                         | 4.40G/9.98G [00:26<00:31, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|███████████████████▉                         | 4.42G/9.98G [00:26<00:32, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████████████████████                         | 4.45G/9.98G [00:26<00:31, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████████████████████▏                        | 4.47G/9.98G [00:26<00:53, 102MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████████████████████▏                        | 4.49G/9.98G [00:26<00:47, 116MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████████████████████▎                        | 4.51G/9.98G [00:27<00:42, 129MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████████████████████▍                        | 4.53G/9.98G [00:27<00:39, 137MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████████████████████▌                        | 4.55G/9.98G [00:27<00:37, 145MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████████████████████▌                        | 4.57G/9.98G [00:27<00:35, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████████████████████▋                        | 4.59G/9.98G [00:27<00:33, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████████████████████▊                        | 4.61G/9.98G [00:27<00:31, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████████████████████▉                        | 4.63G/9.98G [00:27<00:31, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|████████████████████▉                        | 4.66G/9.98G [00:27<00:31, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█████████████████████                        | 4.68G/9.98G [00:28<00:31, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█████████████████████▏                       | 4.70G/9.98G [00:28<00:30, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█████████████████████▎                       | 4.72G/9.98G [00:28<00:30, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█████████████████████▍                       | 4.74G/9.98G [00:28<00:30, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█████████████████████▍                       | 4.76G/9.98G [00:28<00:29, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█████████████████████▌                       | 4.78G/9.98G [00:28<00:29, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█████████████████████▋                       | 4.80G/9.98G [00:28<00:28, 181MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█████████████████████▊                       | 4.82G/9.98G [00:28<00:28, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█████████████████████▊                       | 4.84G/9.98G [00:29<00:29, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█████████████████████▉                       | 4.87G/9.98G [00:29<00:44, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|██████████████████████                       | 4.89G/9.98G [00:29<00:39, 128MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|██████████████████████▏                      | 4.91G/9.98G [00:29<00:37, 137MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|██████████████████████▏                      | 4.93G/9.98G [00:29<00:34, 145MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██████████████████████▎                      | 4.95G/9.98G [00:29<00:32, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██████████████████████▍                      | 4.97G/9.98G [00:29<00:31, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██████████████████████▌                      | 4.99G/9.98G [00:30<00:30, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██████████████████████▌                      | 5.01G/9.98G [00:30<00:29, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██████████████████████▋                      | 5.03G/9.98G [00:30<00:29, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██████████████████████▊                      | 5.05G/9.98G [00:30<00:28, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██████████████████████▉                      | 5.08G/9.98G [00:30<00:28, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██████████████████████▉                      | 5.10G/9.98G [00:30<00:28, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|███████████████████████                      | 5.12G/9.98G [00:30<00:27, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|███████████████████████▏                     | 5.14G/9.98G [00:30<00:27, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|███████████████████████▎                     | 5.16G/9.98G [00:31<00:27, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|███████████████████████▎                     | 5.18G/9.98G [00:31<00:27, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|███████████████████████▍                     | 5.20G/9.98G [00:31<00:27, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|███████████████████████▌                     | 5.22G/9.98G [00:31<00:26, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|███████████████████████▋                     | 5.24G/9.98G [00:31<00:27, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|███████████████████████▋                     | 5.26G/9.98G [00:31<00:26, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|███████████████████████▊                     | 5.28G/9.98G [00:31<00:27, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|███████████████████████▉                     | 5.31G/9.98G [00:31<00:27, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|████████████████████████                     | 5.33G/9.98G [00:32<00:27, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|████████████████████████                     | 5.35G/9.98G [00:32<00:27, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|████████████████████████▏                    | 5.37G/9.98G [00:32<00:27, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|████████████████████████▎                    | 5.39G/9.98G [00:32<00:27, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|████████████████████████▍                    | 5.41G/9.98G [00:32<00:27, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|████████████████████████▍                    | 5.43G/9.98G [00:32<00:27, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|████████████████████████▌                    | 5.45G/9.98G [00:32<00:26, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|████████████████████████▋                    | 5.47G/9.98G [00:32<00:25, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|████████████████████████▊                    | 5.49G/9.98G [00:32<00:24, 182MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|████████████████████████▉                    | 5.52G/9.98G [00:33<00:25, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|████████████████████████▉                    | 5.54G/9.98G [00:33<00:24, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████████████████████████                    | 5.56G/9.98G [00:33<00:25, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████████████████████████▏                   | 5.58G/9.98G [00:33<00:25, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████████████████████████▎                   | 5.60G/9.98G [00:33<00:25, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████████████████████████▎                   | 5.62G/9.98G [00:33<00:25, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████████████████████████▍                   | 5.64G/9.98G [00:33<00:25, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████████████████████████▌                   | 5.66G/9.98G [00:33<00:25, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████████████████████████▋                   | 5.68G/9.98G [00:34<00:25, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████████████████████████▋                   | 5.70G/9.98G [00:34<00:25, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████████████████████████▊                   | 5.73G/9.98G [00:34<00:25, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|█████████████████████████▉                   | 5.75G/9.98G [00:34<00:24, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██████████████████████████                   | 5.77G/9.98G [00:34<00:24, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██████████████████████████                   | 5.79G/9.98G [00:34<00:24, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██████████████████████████▏                  | 5.81G/9.98G [00:34<00:24, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██████████████████████████▎                  | 5.83G/9.98G [00:34<00:23, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██████████████████████████▍                  | 5.85G/9.98G [00:35<00:23, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██████████████████████████▍                  | 5.87G/9.98G [00:35<00:23, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██████████████████████████▌                  | 5.89G/9.98G [00:35<00:23, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██████████████████████████▋                  | 5.91G/9.98G [00:35<00:23, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██████████████████████████▊                  | 5.93G/9.98G [00:35<00:23, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██████████████████████████▊                  | 5.96G/9.98G [00:35<00:23, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██████████████████████████▉                  | 5.98G/9.98G [00:35<00:22, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|███████████████████████████                  | 6.00G/9.98G [00:35<00:23, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|███████████████████████████▏                 | 6.02G/9.98G [00:36<00:22, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|███████████████████████████▏                 | 6.04G/9.98G [00:36<00:23, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|███████████████████████████▎                 | 6.06G/9.98G [00:36<00:22, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|███████████████████████████▍                 | 6.08G/9.98G [00:36<00:22, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|███████████████████████████▌                 | 6.10G/9.98G [00:36<00:22, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|███████████████████████████▌                 | 6.12G/9.98G [00:36<00:22, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|███████████████████████████▋                 | 6.14G/9.98G [00:36<00:22, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|███████████████████████████▊                 | 6.17G/9.98G [00:36<00:22, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|███████████████████████████▉                 | 6.19G/9.98G [00:36<00:22, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|███████████████████████████▉                 | 6.21G/9.98G [00:37<00:21, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|████████████████████████████                 | 6.23G/9.98G [00:37<00:21, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|████████████████████████████▏                | 6.25G/9.98G [00:37<00:22, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|████████████████████████████▎                | 6.27G/9.98G [00:37<00:22, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|████████████████████████████▍                | 6.29G/9.98G [00:37<00:22, 162MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|████████████████████████████▍                | 6.31G/9.98G [00:37<00:22, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|████████████████████████████▌                | 6.33G/9.98G [00:37<00:22, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|████████████████████████████▋                | 6.35G/9.98G [00:38<00:22, 164MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|████████████████████████████▊                | 6.38G/9.98G [00:38<00:21, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|████████████████████████████▊                | 6.40G/9.98G [00:38<00:21, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|████████████████████████████▉                | 6.42G/9.98G [00:38<00:21, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|█████████████████████████████                | 6.44G/9.98G [00:38<00:21, 167MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|█████████████████████████████▏               | 6.46G/9.98G [00:38<00:20, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|█████████████████████████████▏               | 6.48G/9.98G [00:38<00:20, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|█████████████████████████████▎               | 6.50G/9.98G [00:38<00:20, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|█████████████████████████████▍               | 6.52G/9.98G [00:39<00:20, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|█████████████████████████████▌               | 6.54G/9.98G [00:39<00:19, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|█████████████████████████████▌               | 6.56G/9.98G [00:39<00:19, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|█████████████████████████████▋               | 6.59G/9.98G [00:39<00:19, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|█████████████████████████████▊               | 6.61G/9.98G [00:39<00:19, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|█████████████████████████████▉               | 6.63G/9.98G [00:39<00:19, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|█████████████████████████████▉               | 6.65G/9.98G [00:39<00:19, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████████████████████████████               | 6.67G/9.98G [00:39<00:19, 171MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████████████████████████████▏              | 6.69G/9.98G [00:39<00:19, 172MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████████████████████████████▎              | 6.71G/9.98G [00:40<00:18, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████████████████████████████▎              | 6.73G/9.98G [00:40<00:18, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██████████████████████████████▍              | 6.75G/9.98G [00:40<00:18, 174MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██████████████████████████████▌              | 6.77G/9.98G [00:40<00:18, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██████████████████████████████▋              | 6.79G/9.98G [00:40<00:18, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██████████████████████████████▋              | 6.82G/9.98G [00:40<00:18, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██████████████████████████████▊              | 6.84G/9.98G [00:40<00:18, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██████████████████████████████▉              | 6.86G/9.98G [00:40<00:18, 165MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|███████████████████████████████              | 6.88G/9.98G [00:41<00:19, 162MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|███████████████████████████████              | 6.90G/9.98G [00:41<00:19, 162MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|███████████████████████████████▏             | 6.92G/9.98G [00:41<00:19, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████████████████████████████▎             | 6.94G/9.98G [00:41<00:19, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████████████████████████████▍             | 6.96G/9.98G [00:41<00:19, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████████████████████████████▍             | 6.98G/9.98G [00:41<00:19, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████████████████████████████▌             | 7.00G/9.98G [00:41<00:19, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████████████████████████████▋             | 7.03G/9.98G [00:42<00:19, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|███████████████████████████████▊             | 7.05G/9.98G [00:42<00:19, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|███████████████████████████████▉             | 7.07G/9.98G [00:42<00:18, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|███████████████████████████████▉             | 7.09G/9.98G [00:42<00:19, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|████████████████████████████████             | 7.11G/9.98G [00:42<00:19, 144MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|████████████████████████████████▏            | 7.13G/9.98G [00:42<00:19, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|████████████████████████████████▎            | 7.15G/9.98G [00:42<00:19, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|████████████████████████████████▎            | 7.17G/9.98G [00:43<00:19, 145MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|████████████████████████████████▍            | 7.19G/9.98G [00:43<00:18, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|████████████████████████████████▌            | 7.21G/9.98G [00:43<00:18, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|████████████████████████████████▋            | 7.24G/9.98G [00:43<00:17, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|████████████████████████████████▋            | 7.26G/9.98G [00:43<00:17, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|████████████████████████████████▊            | 7.28G/9.98G [00:43<00:17, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|████████████████████████████████▉            | 7.30G/9.98G [00:43<00:17, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|█████████████████████████████████            | 7.32G/9.98G [00:44<00:17, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|█████████████████████████████████            | 7.34G/9.98G [00:44<00:17, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|█████████████████████████████████▏           | 7.36G/9.98G [00:44<00:17, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|█████████████████████████████████▎           | 7.38G/9.98G [00:44<00:16, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|█████████████████████████████████▍           | 7.40G/9.98G [00:44<00:16, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|█████████████████████████████████▍           | 7.42G/9.98G [00:44<00:16, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|█████████████████████████████████▌           | 7.44G/9.98G [00:44<00:16, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|█████████████████████████████████▋           | 7.47G/9.98G [00:44<00:16, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|█████████████████████████████████▊           | 7.49G/9.98G [00:45<00:16, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|█████████████████████████████████▊           | 7.51G/9.98G [00:45<00:16, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|█████████████████████████████████▉           | 7.53G/9.98G [00:45<00:16, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|██████████████████████████████████           | 7.55G/9.98G [00:45<00:15, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|██████████████████████████████████▏          | 7.57G/9.98G [00:45<00:15, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|██████████████████████████████████▏          | 7.59G/9.98G [00:45<00:15, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|██████████████████████████████████▎          | 7.61G/9.98G [00:45<00:15, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|██████████████████████████████████▍          | 7.63G/9.98G [00:46<00:15, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|██████████████████████████████████▌          | 7.65G/9.98G [00:46<00:15, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|██████████████████████████████████▌          | 7.68G/9.98G [00:46<00:14, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|██████████████████████████████████▋          | 7.70G/9.98G [00:46<00:14, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|██████████████████████████████████▊          | 7.72G/9.98G [00:46<00:14, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|██████████████████████████████████▉          | 7.74G/9.98G [00:46<00:14, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|██████████████████████████████████▉          | 7.76G/9.98G [00:46<00:14, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███████████████████████████████████          | 7.78G/9.98G [00:46<00:14, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███████████████████████████████████▏         | 7.80G/9.98G [00:47<00:14, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███████████████████████████████████▎         | 7.82G/9.98G [00:47<00:14, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████████████████████████████████▍         | 7.84G/9.98G [00:47<00:13, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████████████████████████████████▍         | 7.86G/9.98G [00:47<00:13, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████████████████████████████████▌         | 7.89G/9.98G [00:47<00:13, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████████████████████████████████▋         | 7.91G/9.98G [00:47<00:13, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████████████████████████████████▊         | 7.93G/9.98G [00:47<00:13, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███████████████████████████████████▊         | 7.95G/9.98G [00:48<00:19, 106MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███████████████████████████████████▉         | 7.97G/9.98G [00:48<00:17, 117MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|████████████████████████████████████         | 7.99G/9.98G [00:48<00:15, 126MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|████████████████████████████████████▏        | 8.01G/9.98G [00:48<00:14, 134MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████████████████████████████████▏        | 8.03G/9.98G [00:48<00:13, 146MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████████████████████████████████▎        | 8.05G/9.98G [00:48<00:13, 148MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████████████████████████████████▍        | 8.07G/9.98G [00:49<00:12, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████████████████████████████████▌        | 8.10G/9.98G [00:49<00:12, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████████████████████████████████▌        | 8.12G/9.98G [00:49<00:12, 151MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████████████████████████████████▋        | 8.14G/9.98G [00:49<00:12, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████████████████████████████████▊        | 8.16G/9.98G [00:49<00:11, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████████████████████████████████▉        | 8.18G/9.98G [00:49<00:11, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████████████████████████████████▉        | 8.20G/9.98G [00:49<00:11, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|█████████████████████████████████████        | 8.22G/9.98G [00:50<00:11, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|█████████████████████████████████████▏       | 8.24G/9.98G [00:50<00:11, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|█████████████████████████████████████▎       | 8.26G/9.98G [00:50<00:11, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|█████████████████████████████████████▎       | 8.28G/9.98G [00:50<00:11, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|█████████████████████████████████████▍       | 8.30G/9.98G [00:50<00:10, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|█████████████████████████████████████▌       | 8.33G/9.98G [00:50<00:10, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|█████████████████████████████████████▋       | 8.35G/9.98G [00:50<00:10, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|█████████████████████████████████████▋       | 8.37G/9.98G [00:50<00:10, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|█████████████████████████████████████▊       | 8.39G/9.98G [00:51<00:10, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|█████████████████████████████████████▉       | 8.41G/9.98G [00:51<00:10, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|██████████████████████████████████████       | 8.43G/9.98G [00:51<00:09, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|██████████████████████████████████████       | 8.45G/9.98G [00:51<00:09, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|██████████████████████████████████████▏      | 8.47G/9.98G [00:51<00:09, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|██████████████████████████████████████▎      | 8.49G/9.98G [00:51<00:09, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|██████████████████████████████████████▍      | 8.51G/9.98G [00:51<00:09, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|██████████████████████████████████████▍      | 8.54G/9.98G [00:52<00:09, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|██████████████████████████████████████▌      | 8.56G/9.98G [00:52<00:09, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|██████████████████████████████████████▋      | 8.58G/9.98G [00:52<00:08, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|██████████████████████████████████████▊      | 8.60G/9.98G [00:52<00:08, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|██████████████████████████████████████▉      | 8.62G/9.98G [00:52<00:08, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|██████████████████████████████████████▉      | 8.64G/9.98G [00:52<00:09, 137MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███████████████████████████████████████      | 8.66G/9.98G [00:52<00:09, 139MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███████████████████████████████████████▏     | 8.68G/9.98G [00:53<00:08, 147MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███████████████████████████████████████▎     | 8.70G/9.98G [00:53<00:08, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███████████████████████████████████████▎     | 8.72G/9.98G [00:53<00:08, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███████████████████████████████████████▍     | 8.75G/9.98G [00:53<00:08, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███████████████████████████████████████▌     | 8.77G/9.98G [00:53<00:08, 151MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███████████████████████████████████████▋     | 8.79G/9.98G [00:53<00:07, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███████████████████████████████████████▋     | 8.81G/9.98G [00:53<00:07, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███████████████████████████████████████▊     | 8.83G/9.98G [00:54<00:07, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███████████████████████████████████████▉     | 8.85G/9.98G [00:54<00:07, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|████████████████████████████████████████     | 8.87G/9.98G [00:54<00:07, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|████████████████████████████████████████     | 8.89G/9.98G [00:54<00:07, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|████████████████████████████████████████▏    | 8.91G/9.98G [00:54<00:06, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|████████████████████████████████████████▎    | 8.93G/9.98G [00:54<00:06, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|████████████████████████████████████████▍    | 8.95G/9.98G [00:54<00:06, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|████████████████████████████████████████▍    | 8.98G/9.98G [00:54<00:06, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|████████████████████████████████████████▌    | 9.00G/9.98G [00:55<00:06, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|████████████████████████████████████████▋    | 9.02G/9.98G [00:55<00:06, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|████████████████████████████████████████▊    | 9.04G/9.98G [00:55<00:05, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|████████████████████████████████████████▊    | 9.06G/9.98G [00:55<00:05, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|████████████████████████████████████████▉    | 9.08G/9.98G [00:55<00:05, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████████████████████████████████████    | 9.10G/9.98G [00:55<00:05, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████████████████████████████████████▏   | 9.12G/9.98G [00:55<00:05, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████████████████████████████████████▏   | 9.14G/9.98G [00:56<00:05, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████████████████████████████████████▎   | 9.16G/9.98G [00:56<00:05, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████████████████████████████████████▍   | 9.19G/9.98G [00:56<00:05, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████████████████████████████████████▌   | 9.21G/9.98G [00:56<00:04, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████████████████████████████████████▌   | 9.23G/9.98G [00:56<00:04, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████████████████████████████████████▋   | 9.25G/9.98G [00:56<00:04, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████████████████████████████████████▊   | 9.27G/9.98G [00:56<00:04, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████████████████████████████████████▉   | 9.29G/9.98G [00:56<00:04, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████████████████████████████████████▉   | 9.31G/9.98G [00:57<00:04, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|██████████████████████████████████████████   | 9.33G/9.98G [00:57<00:04, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|██████████████████████████████████████████▏  | 9.35G/9.98G [00:57<00:03, 159MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|██████████████████████████████████████████▎  | 9.37G/9.98G [00:57<00:03, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|██████████████████████████████████████████▍  | 9.40G/9.98G [00:57<00:03, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|██████████████████████████████████████████▍  | 9.42G/9.98G [00:57<00:03, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|██████████████████████████████████████████▌  | 9.44G/9.98G [00:57<00:03, 147MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|██████████████████████████████████████████▋  | 9.46G/9.98G [00:58<00:03, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|██████████████████████████████████████████▊  | 9.48G/9.98G [00:58<00:03, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|██████████████████████████████████████████▊  | 9.50G/9.98G [00:58<00:03, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|██████████████████████████████████████████▉  | 9.52G/9.98G [00:58<00:02, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███████████████████████████████████████████  | 9.54G/9.98G [00:58<00:02, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███████████████████████████████████████████▏ | 9.56G/9.98G [00:58<00:02, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███████████████████████████████████████████▏ | 9.58G/9.98G [00:58<00:02, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███████████████████████████████████████████▎ | 9.60G/9.98G [00:59<00:02, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███████████████████████████████████████████▍ | 9.63G/9.98G [00:59<00:02, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███████████████████████████████████████████▌ | 9.65G/9.98G [00:59<00:02, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███████████████████████████████████████████▌ | 9.67G/9.98G [00:59<00:01, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███████████████████████████████████████████▋ | 9.69G/9.98G [00:59<00:01, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███████████████████████████████████████████▊ | 9.71G/9.98G [00:59<00:01, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███████████████████████████████████████████▉ | 9.73G/9.98G [00:59<00:01, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███████████████████████████████████████████▉ | 9.75G/9.98G [00:59<00:01, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|████████████████████████████████████████████ | 9.77G/9.98G [01:00<00:01, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|████████████████████████████████████████████▏| 9.79G/9.98G [01:00<00:01, 153MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|████████████████████████████████████████████▎| 9.81G/9.98G [01:00<00:01, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|████████████████████████████████████████████▎| 9.84G/9.98G [01:00<00:00, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|████████████████████████████████████████████▍| 9.86G/9.98G [01:00<00:00, 158MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|████████████████████████████████████████████▌| 9.88G/9.98G [01:00<00:00, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|████████████████████████████████████████████▋| 9.90G/9.98G [01:00<00:00, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|████████████████████████████████████████████▋| 9.92G/9.98G [01:01<00:00, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|████████████████████████████████████████████▊| 9.94G/9.98G [01:01<00:00, 155MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|█████████████████████████████████████████████| 9.98G/9.98G [01:01<00:00, 162MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████████████████████████▌                                | 1/2 [01:01<01:01, 61.64s/it]\n",
      "model-00002-of-00002.safetensors:   0%|                                                     | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1%|▎                                            | 21.0M/3.50G [00:00<00:26, 131MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1%|▌                                            | 41.9M/3.50G [00:00<00:24, 143MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2%|▊                                            | 62.9M/3.50G [00:00<00:23, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2%|█                                            | 83.9M/3.50G [00:00<00:22, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   3%|█▍                                            | 105M/3.50G [00:00<00:31, 109MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   4%|█▋                                            | 126M/3.50G [00:00<00:27, 121MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   4%|█▉                                            | 147M/3.50G [00:01<00:24, 136MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5%|██▏                                           | 168M/3.50G [00:01<00:23, 142MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5%|██▍                                           | 189M/3.50G [00:01<00:22, 144MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6%|██▊                                           | 210M/3.50G [00:01<00:22, 146MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7%|███                                           | 231M/3.50G [00:01<00:22, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7%|███▎                                          | 252M/3.50G [00:01<00:21, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8%|███▌                                          | 273M/3.50G [00:01<00:21, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8%|███▊                                          | 294M/3.50G [00:02<00:21, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9%|████▏                                         | 315M/3.50G [00:02<00:20, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10%|████▍                                         | 336M/3.50G [00:02<00:20, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10%|████▋                                         | 357M/3.50G [00:02<00:20, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11%|████▉                                         | 377M/3.50G [00:02<00:20, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11%|█████▏                                        | 398M/3.50G [00:02<00:20, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12%|█████▌                                        | 419M/3.50G [00:02<00:19, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13%|█████▊                                        | 440M/3.50G [00:03<00:19, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13%|██████                                        | 461M/3.50G [00:03<00:19, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14%|██████▎                                       | 482M/3.50G [00:03<00:19, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14%|██████▌                                       | 503M/3.50G [00:03<00:19, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15%|██████▉                                       | 524M/3.50G [00:03<00:19, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16%|███████▏                                      | 545M/3.50G [00:03<00:19, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16%|███████▍                                      | 566M/3.50G [00:03<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17%|███████▋                                      | 587M/3.50G [00:03<00:18, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17%|███████▉                                      | 608M/3.50G [00:04<00:19, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  18%|████████▎                                     | 629M/3.50G [00:04<00:18, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19%|████████▌                                     | 650M/3.50G [00:04<00:18, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19%|████████▊                                     | 671M/3.50G [00:04<00:18, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20%|█████████                                     | 692M/3.50G [00:04<00:18, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20%|█████████▎                                    | 713M/3.50G [00:04<00:18, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  21%|█████████▋                                    | 734M/3.50G [00:04<00:18, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22%|█████████▉                                    | 755M/3.50G [00:05<00:20, 133MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22%|██████████▏                                   | 776M/3.50G [00:05<00:19, 139MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23%|██████████▍                                   | 797M/3.50G [00:05<00:18, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23%|██████████▋                                   | 818M/3.50G [00:05<00:17, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24%|███████████                                   | 839M/3.50G [00:05<00:17, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25%|███████████▎                                  | 860M/3.50G [00:05<00:17, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25%|███████████▌                                  | 881M/3.50G [00:05<00:17, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26%|███████████▊                                  | 902M/3.50G [00:06<00:16, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26%|████████████▏                                 | 923M/3.50G [00:06<00:16, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27%|████████████▍                                 | 944M/3.50G [00:06<00:16, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28%|████████████▋                                 | 965M/3.50G [00:06<00:15, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28%|████████████▉                                 | 986M/3.50G [00:06<00:15, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29%|████████████▉                                | 1.01G/3.50G [00:06<00:15, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29%|█████████████▏                               | 1.03G/3.50G [00:06<00:16, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30%|█████████████▍                               | 1.05G/3.50G [00:07<00:16, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31%|█████████████▊                               | 1.07G/3.50G [00:07<00:16, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31%|██████████████                               | 1.09G/3.50G [00:07<00:15, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32%|██████████████▎                              | 1.11G/3.50G [00:07<00:15, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32%|██████████████▌                              | 1.13G/3.50G [00:07<00:14, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33%|██████████████▊                              | 1.15G/3.50G [00:07<00:14, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34%|███████████████                              | 1.17G/3.50G [00:07<00:14, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34%|███████████████▎                             | 1.20G/3.50G [00:07<00:14, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35%|███████████████▋                             | 1.22G/3.50G [00:08<00:15, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35%|███████████████▉                             | 1.24G/3.50G [00:08<00:15, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36%|████████████████▏                            | 1.26G/3.50G [00:08<00:14, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37%|████████████████▍                            | 1.28G/3.50G [00:08<00:14, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37%|████████████████▋                            | 1.30G/3.50G [00:08<00:14, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38%|████████████████▉                            | 1.32G/3.50G [00:08<00:14, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38%|█████████████████▎                           | 1.34G/3.50G [00:08<00:13, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39%|█████████████████▌                           | 1.36G/3.50G [00:09<00:13, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40%|█████████████████▊                           | 1.38G/3.50G [00:09<00:13, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40%|██████████████████                           | 1.41G/3.50G [00:09<00:13, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41%|██████████████████▎                          | 1.43G/3.50G [00:09<00:13, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41%|██████████████████▌                          | 1.45G/3.50G [00:09<00:13, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  42%|██████████████████▊                          | 1.47G/3.50G [00:09<00:12, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43%|███████████████████▏                         | 1.49G/3.50G [00:09<00:12, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43%|███████████████████▍                         | 1.51G/3.50G [00:09<00:12, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44%|███████████████████▋                         | 1.53G/3.50G [00:10<00:12, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44%|███████████████████▉                         | 1.55G/3.50G [00:10<00:12, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45%|████████████████████▏                        | 1.57G/3.50G [00:10<00:16, 120MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46%|████████████████████▍                        | 1.59G/3.50G [00:10<00:16, 113MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46%|████████████████████▎                       | 1.61G/3.50G [00:11<00:21, 89.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47%|████████████████████▌                       | 1.64G/3.50G [00:11<00:19, 97.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47%|████████████████████▊                       | 1.66G/3.50G [00:11<00:19, 96.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48%|█████████████████████▌                       | 1.68G/3.50G [00:11<00:16, 109MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49%|█████████████████████▊                       | 1.70G/3.50G [00:11<00:15, 115MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49%|██████████████████████                       | 1.72G/3.50G [00:12<00:16, 106MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50%|█████████████████████▉                      | 1.74G/3.50G [00:12<00:18, 97.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50%|██████████████████████                      | 1.75G/3.50G [00:12<00:18, 94.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  51%|██████████████████████▊                      | 1.77G/3.50G [00:12<00:15, 109MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  51%|███████████████████████                      | 1.79G/3.50G [00:12<00:14, 120MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52%|███████████████████████▎                     | 1.81G/3.50G [00:12<00:13, 126MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52%|███████████████████████▌                     | 1.84G/3.50G [00:12<00:12, 137MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  53%|███████████████████████▊                     | 1.86G/3.50G [00:13<00:13, 121MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54%|███████████████████████▌                    | 1.88G/3.50G [00:13<00:16, 96.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54%|███████████████████████▊                    | 1.90G/3.50G [00:13<00:17, 89.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55%|████████████████████████▋                    | 1.92G/3.50G [00:13<00:15, 102MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55%|████████████████████████▉                    | 1.94G/3.50G [00:13<00:13, 116MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56%|█████████████████████████▏                   | 1.96G/3.50G [00:14<00:12, 125MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57%|█████████████████████████▍                   | 1.98G/3.50G [00:14<00:11, 131MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57%|█████████████████████████▋                   | 2.00G/3.50G [00:14<00:10, 138MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58%|██████████████████████████                   | 2.02G/3.50G [00:14<00:10, 143MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58%|██████████████████████████▎                  | 2.04G/3.50G [00:14<00:09, 146MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  59%|██████████████████████████▌                  | 2.07G/3.50G [00:14<00:09, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60%|██████████████████████████▊                  | 2.09G/3.50G [00:14<00:09, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60%|███████████████████████████                  | 2.11G/3.50G [00:15<00:09, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61%|███████████████████████████▎                 | 2.13G/3.50G [00:15<00:08, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61%|███████████████████████████▋                 | 2.15G/3.50G [00:15<00:08, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62%|███████████████████████████▉                 | 2.17G/3.50G [00:15<00:08, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63%|████████████████████████████▏                | 2.19G/3.50G [00:15<00:08, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63%|████████████████████████████▍                | 2.21G/3.50G [00:15<00:08, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64%|████████████████████████████▋                | 2.23G/3.50G [00:15<00:08, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64%|████████████████████████████▉                | 2.25G/3.50G [00:16<00:08, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65%|█████████████████████████████▎               | 2.28G/3.50G [00:16<00:07, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66%|█████████████████████████████▌               | 2.30G/3.50G [00:16<00:07, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66%|█████████████████████████████▊               | 2.32G/3.50G [00:16<00:07, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67%|██████████████████████████████               | 2.34G/3.50G [00:16<00:07, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67%|██████████████████████████████▎              | 2.36G/3.50G [00:16<00:07, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  68%|██████████████████████████████▌              | 2.38G/3.50G [00:16<00:07, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69%|██████████████████████████████▊              | 2.40G/3.50G [00:16<00:07, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69%|███████████████████████████████▏             | 2.42G/3.50G [00:17<00:06, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70%|███████████████████████████████▍             | 2.44G/3.50G [00:17<00:06, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70%|███████████████████████████████▋             | 2.46G/3.50G [00:17<00:06, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71%|███████████████████████████████▉             | 2.49G/3.50G [00:17<00:06, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72%|████████████████████████████████▏            | 2.51G/3.50G [00:17<00:06, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72%|████████████████████████████████▍            | 2.53G/3.50G [00:17<00:07, 136MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73%|████████████████████████████████▊            | 2.55G/3.50G [00:17<00:06, 141MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73%|█████████████████████████████████            | 2.57G/3.50G [00:18<00:06, 145MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74%|█████████████████████████████████▎           | 2.59G/3.50G [00:18<00:06, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75%|█████████████████████████████████▌           | 2.61G/3.50G [00:18<00:05, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75%|█████████████████████████████████▊           | 2.63G/3.50G [00:18<00:05, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76%|██████████████████████████████████           | 2.65G/3.50G [00:18<00:05, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76%|██████████████████████████████████▍          | 2.67G/3.50G [00:18<00:05, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  77%|██████████████████████████████████▋          | 2.69G/3.50G [00:18<00:05, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|██████████████████████████████████▉          | 2.72G/3.50G [00:19<00:05, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|███████████████████████████████████▏         | 2.74G/3.50G [00:19<00:04, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  79%|███████████████████████████████████▍         | 2.76G/3.50G [00:19<00:04, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  79%|███████████████████████████████████▋         | 2.78G/3.50G [00:19<00:04, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80%|███████████████████████████████████▉         | 2.80G/3.50G [00:19<00:04, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81%|████████████████████████████████████▎        | 2.82G/3.50G [00:19<00:04, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81%|████████████████████████████████████▌        | 2.84G/3.50G [00:19<00:04, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82%|████████████████████████████████████▊        | 2.86G/3.50G [00:19<00:04, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82%|█████████████████████████████████████        | 2.88G/3.50G [00:20<00:03, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83%|█████████████████████████████████████▎       | 2.90G/3.50G [00:20<00:03, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84%|█████████████████████████████████████▌       | 2.93G/3.50G [00:20<00:03, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84%|█████████████████████████████████████▉       | 2.95G/3.50G [00:20<00:03, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85%|██████████████████████████████████████▏      | 2.97G/3.50G [00:20<00:03, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85%|██████████████████████████████████████▍      | 2.99G/3.50G [00:20<00:03, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86%|██████████████████████████████████████▋      | 3.01G/3.50G [00:20<00:03, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|██████████████████████████████████████▉      | 3.03G/3.50G [00:21<00:03, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|███████████████████████████████████████▏     | 3.05G/3.50G [00:21<00:02, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88%|███████████████████████████████████████▍     | 3.07G/3.50G [00:21<00:02, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88%|███████████████████████████████████████▊     | 3.09G/3.50G [00:21<00:02, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89%|████████████████████████████████████████     | 3.11G/3.50G [00:21<00:02, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  90%|████████████████████████████████████████▎    | 3.14G/3.50G [00:21<00:02, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  90%|████████████████████████████████████████▌    | 3.16G/3.50G [00:21<00:02, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91%|████████████████████████████████████████▊    | 3.18G/3.50G [00:22<00:02, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91%|█████████████████████████████████████████    | 3.20G/3.50G [00:22<00:01, 151MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92%|█████████████████████████████████████████▍   | 3.22G/3.50G [00:22<00:01, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93%|█████████████████████████████████████████▋   | 3.24G/3.50G [00:22<00:01, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93%|█████████████████████████████████████████▉   | 3.26G/3.50G [00:22<00:01, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94%|██████████████████████████████████████████▏  | 3.28G/3.50G [00:22<00:01, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94%|██████████████████████████████████████████▍  | 3.30G/3.50G [00:22<00:01, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95%|██████████████████████████████████████████▋  | 3.32G/3.50G [00:22<00:01, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96%|███████████████████████████████████████████  | 3.34G/3.50G [00:23<00:00, 156MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96%|███████████████████████████████████████████▎ | 3.37G/3.50G [00:23<00:00, 155MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97%|███████████████████████████████████████████▌ | 3.39G/3.50G [00:23<00:00, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97%|███████████████████████████████████████████▊ | 3.41G/3.50G [00:23<00:00, 154MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98%|████████████████████████████████████████████ | 3.43G/3.50G [00:23<00:00, 157MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99%|████████████████████████████████████████████▎| 3.45G/3.50G [00:23<00:00, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99%|████████████████████████████████████████████▌| 3.47G/3.50G [00:23<00:00, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|█████████████████████████████████████████████| 3.50G/3.50G [00:24<00:00, 145MB/s]\u001b[A\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████████| 2/2 [01:25<00:00, 42.96s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [01:42<00:00, 51.35s/it]\n",
      "generation_config.json: 100%|██████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 1.38MB/s]\n",
      "pytorch_model.bin.index.json: 100%|█████████████████████████████████████████████████| 26.8k/26.8k [00:00<00:00, 141MB/s]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:44<00:00, 22.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import GenerationConfig\n",
    "from accelerate import Accelerator\n",
    "\n",
    "current_device = Accelerator().local_process_index\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"auto\",) \n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"auto\",) \n",
    "\n",
    "# model.generation_config = GenerationConfig.from_pretrained(config.model_name, \n",
    "#                                                            pad_token_id=tokenizer.pad_token_id,\n",
    "#                                                            top_k=0.0, \n",
    "#                                                            top_p=1.0,\n",
    "#                                                            do_sample=True,\n",
    "#                                                            max_new_tokens=512,\n",
    "#                                                            eos_token_id=-1\n",
    "#                                                           )\n",
    "# ref_model.generation_config = GenerationConfig.from_pretrained(config.model_name, \n",
    "#                                                                pad_token_id=tokenizer.pad_token_id,\n",
    "#                                                                top_k=0.0, \n",
    "#                                                                top_p=1.0,\n",
    "#                                                                do_sample=True,\n",
    "#                                                                max_new_tokens=512,\n",
    "#                                                                eos_token_id=-1\n",
    "#                                                               )\n",
    "# model.to('cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PPOTrainer\n",
    "The `PPOTrainer` takes care of device placement and optimization later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /mnt/ceph/storage/data-tmp/current/hj80pahi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/llm-detector-counter/wandb/run-20240224_125121-twvfruw7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hasanjbara/trl/runs/twvfruw7' target=\"_blank\">crisp-sea-64</a></strong> to <a href='https://wandb.ai/hasanjbara/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hasanjbara/trl' target=\"_blank\">https://wandb.ai/hasanjbara/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hasanjbara/trl/runs/twvfruw7' target=\"_blank\">https://wandb.ai/hasanjbara/trl/runs/twvfruw7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPOTrainer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_data_collator\n\u001b[0;32m----> 4\u001b[0m ppo_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mPPOTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:316\u001b[0m, in \u001b[0;36mPPOTrainer.__init__\u001b[0;34m(self, config, model, ref_model, tokenizer, dataset, optimizer, data_collator, num_shared_layers, lr_scheduler)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Safety checkers for DS integration\u001b[39;00m\n\u001b[1;32m    306\u001b[0m is_deepspeed_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEEPSPEED\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepspeed_plugin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    310\u001b[0m (\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler,\n\u001b[0;32m--> 316\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_deepspeed_used:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# Quantized models are already set on the correct device\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_peft_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_model\u001b[38;5;241m.\u001b[39mpretrained_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_model\u001b[38;5;241m.\u001b[39mpretrained_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    328\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:1179\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;66;03m# TODO: Look at enabling native TP training directly with a proper config\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1178\u001b[0m     ):\n\u001b[0;32m-> 1179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m         )\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1185\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`."
     ]
    }
   ],
   "source": [
    "from trl import PPOTrainer\n",
    "from transformers import default_data_collator\n",
    "\n",
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from trl.import_utils import is_xpu_available\n",
    "\n",
    "device = ppo_trainer.accelerator.device\n",
    "task, model_name = config.reward_model.split(\":\")\n",
    "\n",
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
    "\n",
    "task, model_name = config.reward_model.split(\":\")\n",
    "classifier_pipe = pipeline(task, model=model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tokenizers like GPT-2's don't have a padding token by default, so we set one here.\n",
    "if classifier_pipe.tokenizer.pad_token_id is None:\n",
    "    classifier_pipe.tokenizer.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if classifier_pipe.model.config.pad_token_id is None:\n",
    "    classifier_pipe.model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs are the logits for the negative and positive class. We will use the logits for positive class as a reward signal for the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really bad!!\"\n",
    "test = classifier_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0][0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this movie was really good!!\"\n",
    "classifier_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation settings\n",
    "For the response generation we just use sampling and make sure top-k and nucleus sampling are turned off as well as a minimal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    # \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \"eos_token_id\": 100_000,\n",
    "    \"max_new_tokens\": 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ppo_trainer.dataloader))\n",
    "# query_tensors = batch[\"input_ids\"]\n",
    "query_tensors = torch.LongTensor([q.tolist() for q in batch['input_ids']]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors = model.generate(\n",
    "    query_tensors,\n",
    "    return_dict_in_generate=False,\n",
    "    generation_config=model.generation_config\n",
    ")\n",
    "ref_response_tensors = ref_model.generate(\n",
    "    query_tensors,\n",
    "    return_dict_in_generate=False,\n",
    "    generation_config=ref_model.generation_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_repsonse_from_qwen_batch\n",
    "\n",
    "batch[\"response\"] = get_repsonse_from_qwen_batch(tokenizer, response_tensors, query_tensors, batch['query'])\n",
    "batch[\"ref_response\"] = get_repsonse_from_qwen_batch(tokenizer, response_tensors, query_tensors, batch['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get response from model\n",
    "response_tensors, ref_response_tensors = ppo_trainer.generate(\n",
    "    query_tensors, return_prompt=False, generate_ref_response=True, **model.generation_config.to_dict()\n",
    ")\n",
    "batch[\"response\"] = tokenizer.batch_decode(response_tensors)\n",
    "batch[\"ref_response\"] = tokenizer.batch_decode(ref_response_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentiment score\n",
    "# texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "# pipe_outputs = classifier_pipe(texts, **sent_kwargs)\n",
    "pipe_outputs = classifier_pipe(batch['response'], **sent_kwargs)\n",
    "rewards = [torch.tensor(output[0][\"score\"]) for output in pipe_outputs]\n",
    "# ref_texts = [q + r for q, r in zip(batch[\"query\"], batch[\"ref_response\"])]\n",
    "# ref_pipe_outputs = classifier_pipe(ref_texts, **sent_kwargs)\n",
    "ref_pipe_outputs = classifier_pipe(batch['ref_response'], **sent_kwargs)\n",
    "ref_rewards = [torch.tensor(output[0][\"score\"]) for output in ref_pipe_outputs]\n",
    "batch[\"ref_rewards\"] = ref_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for r in rewards:\n",
    "    total += r\n",
    "print(total/len(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensors_list = [rt for rt in response_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run PPO step\n",
    "stats = ppo_trainer.step(batch[\"input_ids\"], response_tensors_list, rewards) # use batch[\"input_ids\"] instead of query_tensors for weights upate because you need a list here\n",
    "ppo_trainer.log_stats(stats, batch, rewards, columns_to_log=[\"query\", \"response\", \"ref_response\", \"ref_rewards\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop consists of the following main steps:\n",
    "1. Get the query responses from the policy network (GPT-2)\n",
    "2. Get sentiments for query/responses from BERT\n",
    "3. Optimize policy with PPO using the (query, response, reward) triplet\n",
    "\n",
    "**Training time**\n",
    "\n",
    "This step takes **~2h** on a V100 GPU with the above specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from gpt2\n",
    "    response_tensors, ref_response_tensors = ppo_trainer.generate(\n",
    "        query_tensors, return_prompt=False, generate_ref_response=True, **generation_kwargs\n",
    "    )\n",
    "    batch[\"response\"] = tokenizer.batch_decode(response_tensors)\n",
    "    batch[\"ref_response\"] = tokenizer.batch_decode(ref_response_tensors)\n",
    "\n",
    "    # Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = classifier_pipe(texts, **sent_kwargs)\n",
    "    rewards = [torch.tensor(output[0][\"score\"]) for output in pipe_outputs]\n",
    "    ref_texts = [q + r for q, r in zip(batch[\"query\"], batch[\"ref_response\"])]\n",
    "    ref_pipe_outputs = classifier_pipe(ref_texts, **sent_kwargs)\n",
    "    ref_rewards = [torch.tensor(output[0][\"score\"]) for output in ref_pipe_outputs]\n",
    "    batch[\"ref_rewards\"] = ref_rewards\n",
    "\n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards, columns_to_log=[\"query\", \"response\", \"ref_response\", \"ref_rewards\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training progress\n",
    "If you are tracking the training progress with Weights&Biases you should see a plot similar to the one below. Check out the interactive sample report on wandb.ai: [link](https://app.wandb.ai/huggingface/trl-showcase/runs/1jtvxb1m/).\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_tuning_progress.png' width='800'>\n",
    "<p style=\"text-align: center;\"> <b>Figure:</b> Reward mean and distribution evolution during training. </p>\n",
    "</div>\n",
    "\n",
    "One can observe how the model starts to generate more positive outputs after a few optimisation steps.\n",
    "\n",
    "> Note: Investigating the KL-divergence will probably show that at this point the model has not converged to the target KL-divergence, yet. To get there would require longer training or starting with a higher initial coefficient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection\n",
    "Let's inspect some examples from the IMDB dataset. We can use `model_ref` to compare the tuned model `model` against the model before optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the reward mean/median of the generated sequences we observe a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Finally, we save the model and push it to the Hugging Face for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gpt2-imdb-pos-v2\", push_to_hub=True)\n",
    "tokenizer.save_pretrained(\"gpt2-imdb-pos-v2\", push_to_hub=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c8ff454cd947027f86954d72bf940c689a97dcc494eb53cfe4813862c6065fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
